<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Yifan Zhu</title>

    <meta name="author" content="Yifan Zhu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yifan Zhu
                </p>
                <p>
                  I currently work at ByteDance, focusing on the development of advanced 3D vision and augmented reality (AR) technologies. Prior to joining ByteDance, I completed my master's degree from Nankai University, under the supervision of <a href="http://ren-bo.net/"> Bo Ren</a> and <a href="https://mmcheng.net/cmm/">Mingming Cheng</a>. Before that, I received my bachelor's degree from Hebei University of Technology,under the supervision of <a href="https://ieeexplore.ieee.org/author/37539853600">Haiyong Chen</a>
                </p>
                <p style="text-align:center">
                  <a href="mailto:zhuyifan@nankai.mail.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=6abekesAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/yifanzhu314">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:25%;max-width:25%">
                <a href="images/me.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/me.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


    <tr onmouseout="transfusion_stop()" onmouseover="transfution_start()" >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='transfution_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/transfution.jpg" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/transfution.jpg' width="160">
        </div>
        <script type="text/javascript">
          function transfution_start() {
            document.getElementById('transfution_image').style.opacity = "1";
          }

          function transfusion_stop() {
            document.getElementById('transfution_image').style.opacity = "0";
          }
          transfusion_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhu_Transfusion_A_Novel_SLAM_Method_Focused_on_Transparent_Objects_ICCV_2021_paper.pdf">
          <span class="papertitle">Transfusion: A novel slam method focused on transparent objects          </span>
        </a>
        <br>
        <strong>Yifan Zhu</strong>,
        <a href="https://scholar.google.com/citations?user=hQjoD7kAAAAJ&hl=en">Jiaxiong Qiu</a>,
        <a href="http://ren-bo.net/">Bo Ren</a>
        <br>
        <em>ICCV</em>, 2021
        <br>
        <!-- <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a> -->
        <p></p>
        <p>
		<!-- By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation. -->
        </p>
      </td>
    </tr>

    <tr onmouseout="consistent_stop()" onmouseover="consistent_start()" >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='consistent_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/consistent.jpg" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/consistent.jpg' width="160">
        </div>
        <script type="text/javascript">
          function consistent_start() {
            document.getElementById('consistent_image').style.opacity = "1";
          }

          function consistent_stop() {
            document.getElementById('consistent_image').style.opacity = "0";
          }
          consistent_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="http://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Consistent_Depth_Prediction_for_Transparent_Object_Reconstruction_from_RGB-D_Camera_ICCV_2023_paper.pdf">
          <span class="papertitle">Consistent depth prediction for transparent object reconstruction from rgb-d camera
          </span>
        </a>
        <br>
        Yuxiang Cai,
        <strong>Yifan Zhu</strong>,
        Haiwei Zhang,
        <a href="http://ren-bo.net/">Bo Ren</a>
        <br>
        <em>ICCV</em>, 2023
        <br>
          <!-- <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
          /
          <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a> -->
        <p></p>
        <p>
          <!-- By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation. -->
        </p>
      </td>
    </tr>

    <tr onmouseout="rdnerf_stop()" onmouseover="rdnerf_start()" >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='rdnerf_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/rdnerf.jpg" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/rdnerf.jpg' width="160">
        </div>
        <script type="text/javascript">
          function rdnerf_start() {
            document.getElementById('rdnerf_image').style.opacity = "1";
          }

          function rdnerf_stop() {
            document.getElementById('rdnerf_image').style.opacity = "0";
          }
          rdnerf_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="http://ren-bo.net/papers/qjx_tvcj2023_1.pdf">
          <span class="papertitle">RDNeRF: relative depth guided NeRF for dense free view synthesis
          </span>
        </a>
        <br>
        <a href="https://scholar.google.com/citations?user=hQjoD7kAAAAJ&hl=en">Jiaxiong Qiu</a>,
        <strong>Yifan Zhu</strong>,
        <a href="https://pengtaojiang.github.io/">PengTao Jiang</a>
        <a href="https://mmcheng.net/cmm/">MingMing Cheng</a>
        <a href="http://ren-bo.net/">Bo Ren</a>
        <br>
        <em>The Visual Computer </em>, 2024
        <br>
          <!-- <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
          /
          <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a> -->
        <p></p>
        <p>
          <!-- By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation. -->
        </p>
      </td>
    </tr>


    <tr onmouseout="qjx_cvpr2023_stop()" onmouseover="qjx_cvpr2023_start()" >
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='qjx_cvpr2023_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/qjx_cvpr2023.jpg" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/qjx_cvpr2023.jpg' width="160">
        </div>
        <script type="text/javascript">
          function qjx_cvpr2023_start() {
            document.getElementById('qjx_cvpr2023_image').style.opacity = "1";
          }

          function qjx_cvpr2023_stop() {
            document.getElementById('qjx_cvpr2023_image').style.opacity = "0";
          }
          qjx_cvpr2023_stop()
        </script>
      </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Qiu_Looking_Through_the_Glass_Neural_Surface_Reconstruction_Against_High_Specular_CVPR_2023_paper.pdf">
          <span class="papertitle">Looking through the glass: Neural surface reconstruction against high specular reflections
          </span>
        </a>
        <br>
        <a href="https://scholar.google.com/citations?user=hQjoD7kAAAAJ&hl=en">Jiaxiong Qiu</a>,
        <a href="https://pengtaojiang.github.io/">PengTao Jiang</a>
        <a href="https://scholar.google.com/citations?user=I1BKs78AAAAJ&hl=en">Zexin Yin</a>
        <strong>Yifan Zhu</strong>,
        <a href="https://mmcheng.net/cmm/">MingMing Cheng</a>
        <a href="http://ren-bo.net/">Bo Ren</a>
        <br>
        <em>CVPR</em>, 2023
        <br>
          <!-- <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
          /
          <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a> -->
        <p></p>
        <p>
          <!-- By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation. -->
        </p>
      </td>
    </tr>

      </tbody></table>

          

  </body>
</html>
